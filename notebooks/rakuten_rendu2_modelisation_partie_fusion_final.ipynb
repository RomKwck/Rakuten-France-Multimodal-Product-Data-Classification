{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6fd34e",
   "metadata": {},
   "source": [
    "# **Rakuten France Classification des données des produits multimodaux**\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e71bdd",
   "metadata": {},
   "source": [
    "## 4. Modèle d'agrégation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7288bc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fenzhengrou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import os\n",
    "import statsmodels.api\n",
    "import PIL\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator \n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776f36cb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.1. Import des données pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47fa2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des données pre-processing\n",
    "df = pd.read_csv('rakuten_data_preproc.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242bb172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fenzhengrou\\AppData\\Local\\Temp\\ipykernel_19748\\2771852974.py:2: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  traduction = pd.read_table(\"traduction_designation-description.txt\", header=None, squeeze=True)\n"
     ]
    }
   ],
   "source": [
    "# charger les resultats de traduction\n",
    "traduction = pd.read_table(\"traduction_designation-description.txt\", header=None, squeeze=True)\n",
    "traduction.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083503fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('french') + stopwords.words('english'))\n",
    "mots_vides = [\"x\", \"cm\", \"mm\", \"h\", \"g\", \"peut\", \"être\", 'e',\"l'\",'x','p','re', 'li','x','b','d','h', 'pla','br','id','al','ra','pla','sine','r','g','v','u','f']\n",
    "stop_words.update(mots_vides)\n",
    "\n",
    "\n",
    "def word_split(text):\n",
    "    \"\"\"split text into words, remove non alphabetic tokens and stopwords\"\"\"\n",
    "    \n",
    "    # suppression de la ponctuation\n",
    "    table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    text = text.translate(table)\n",
    "    \n",
    "    # séparation des textes en listes de mots\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # conversion en minuscule\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    # restriction aux charactères alphabétiques\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    # filtrage des stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26778e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# données textuelles netoyées et traduites\n",
    "traduction = traduction.apply(word_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a010d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_data'] = traduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3343593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>image_size</th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>designation_description</th>\n",
       "      <th>avec_description</th>\n",
       "      <th>designation_description_nbr_mot</th>\n",
       "      <th>prdcat</th>\n",
       "      <th>text_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1263597046_product_3804725264.jpg</td>\n",
       "      <td>14010</td>\n",
       "      <td>10</td>\n",
       "      <td>['olivia', 'personalisiertes', 'notizbuch', 's...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Livres</td>\n",
       "      <td>[olivia, personnalisé, carnet, pages, grille, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_1008141237_product_436067568.jpg</td>\n",
       "      <td>14854</td>\n",
       "      <td>2280</td>\n",
       "      <td>['journal', 'arts', 'art', 'marche', 'salon', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Livres</td>\n",
       "      <td>[journal, art, art, marche, salon, art, asiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_938777978_product_201115110.jpg</td>\n",
       "      <td>6898</td>\n",
       "      <td>50</td>\n",
       "      <td>['grand', 'stylet', 'ergonomique', 'bleu', 'ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>Jeux</td>\n",
       "      <td>[grand, stylet, ergonomique, bleu, manette, je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_457047496_product_50418756.jpg</td>\n",
       "      <td>14404</td>\n",
       "      <td>1280</td>\n",
       "      <td>['peluche', 'donald', 'europe', 'disneyland', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Jouets &amp; figurines</td>\n",
       "      <td>[peluche, donald, europe, disneyland, marionne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_1077757786_product_278535884.jpg</td>\n",
       "      <td>20435</td>\n",
       "      <td>2705</td>\n",
       "      <td>['guerre', 'tuques', 'luc', 'grandeur', 'veut'...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>Livres</td>\n",
       "      <td>[guerre, tuques, luc, grandeur, veut, organise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image  image_size  prdtypecode  \\\n",
       "ID                                                                     \n",
       "0   image_1263597046_product_3804725264.jpg       14010           10   \n",
       "1    image_1008141237_product_436067568.jpg       14854         2280   \n",
       "2     image_938777978_product_201115110.jpg        6898           50   \n",
       "3      image_457047496_product_50418756.jpg       14404         1280   \n",
       "4    image_1077757786_product_278535884.jpg       20435         2705   \n",
       "\n",
       "                              designation_description  avec_description  \\\n",
       "ID                                                                        \n",
       "0   ['olivia', 'personalisiertes', 'notizbuch', 's...                 0   \n",
       "1   ['journal', 'arts', 'art', 'marche', 'salon', ...                 0   \n",
       "2   ['grand', 'stylet', 'ergonomique', 'bleu', 'ga...                 1   \n",
       "3   ['peluche', 'donald', 'europe', 'disneyland', ...                 0   \n",
       "4   ['guerre', 'tuques', 'luc', 'grandeur', 'veut'...                 1   \n",
       "\n",
       "    designation_description_nbr_mot              prdcat  \\\n",
       "ID                                                        \n",
       "0                                 9              Livres   \n",
       "1                                20              Livres   \n",
       "2                                80                Jeux   \n",
       "3                                 6  Jouets & figurines   \n",
       "4                                18              Livres   \n",
       "\n",
       "                                            text_data  \n",
       "ID                                                     \n",
       "0   [olivia, personnalisé, carnet, pages, grille, ...  \n",
       "1   [journal, art, art, marche, salon, art, asiati...  \n",
       "2   [grand, stylet, ergonomique, bleu, manette, je...  \n",
       "3   [peluche, donald, europe, disneyland, marionne...  \n",
       "4   [guerre, tuques, luc, grandeur, veut, organise...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece6cef",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Préparation des donnés pour les modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6653da",
   "metadata": {},
   "source": [
    " On sélectionne les colonnes utiles pour la modélisation : texte netoyés et traduits mais sans stemmimg, nom des images, et le code type de produit. En suite, on effectue le même traitement comme dans la partie modélisation de texte et d'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3c2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['text_data', 'image', 'prdtypecode']]\n",
    "y = df['prdtypecode']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "Y = encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62949084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization pour les textes\n",
    "X_train_txt = X_train['text_data'].apply(lambda x : \" \".join(w for w in x))\n",
    "X_test_txt = X_test['text_data'].apply(lambda x : \" \".join(w for w in x))\n",
    "\n",
    "import tensorflow as tf\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_txt)\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = tokenizer.index_word\n",
    "vocab_size = len(word2idx)+1 # ajouter 1 ici pour 0 = padding\n",
    "\n",
    "X_train_txt = tokenizer.texts_to_sequences(X_train_txt)\n",
    "X_test_txt = tokenizer.texts_to_sequences(X_test_txt)\n",
    "\n",
    "max_length = 450\n",
    "X_train_txt = tf.keras.preprocessing.sequence.pad_sequences(X_train_txt, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test_txt = tf.keras.preprocessing.sequence.pad_sequences(X_test_txt, maxlen=max_length, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e9fb31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59883 validated image filenames belonging to 27 classes.\n",
      "Found 14971 validated image filenames belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "# Chargement des dimages\n",
    "X_train_img = X_train[['image', 'prdtypecode']]\n",
    "X_test_img = X_test[['image', 'prdtypecode']] \n",
    "X_train_img['prdtypecode2']=X_train_img['prdtypecode'].astype(str)\n",
    "X_test_img['prdtypecode2']=X_test_img['prdtypecode'].astype(str)\n",
    "\n",
    "# generateur des données d'image\n",
    "import tensorflow as tf\n",
    "\n",
    "path=\"../data/images/image_train/\"\n",
    "\n",
    "width = 240\n",
    "height = 240 # resize \n",
    "batch = 32\n",
    "\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                                                preprocessing_function = None,\n",
    "                                                                #rotation_range = 10,\n",
    "                                                                #width_shift_range = 0.1,\n",
    "                                                                #height_shift_range = 0.1,\n",
    "                                                                #zoom_range = 0.1,\n",
    "                                                                #brightness_range=[0.9, 1.1],\n",
    "                                                                #horizontal_flip = True\n",
    "                                                                )\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                                              preprocessing_function = None\n",
    "                                                              )\n",
    "\n",
    "\n",
    "\n",
    "train_set = train_datagen.flow_from_dataframe(dataframe=X_train_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image\",\n",
    "                                              y_col = 'prdtypecode2',\n",
    "                                              seed=42,\n",
    "                                              class_mode=\"sparse\",\n",
    "                                              target_size = (width, height),\n",
    "                                              batch_size = batch,\n",
    "                                              shuffle=False)\n",
    "\n",
    "test_set = test_datagen.flow_from_dataframe(dataframe=X_test_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image\",\n",
    "                                              y_col = \"prdtypecode2\",\n",
    "                                              class_mode=\"sparse\",\n",
    "                                              seed=42,\n",
    "                                              target_size = (width, height),\n",
    "                                              batch_size = batch,\n",
    "                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b40c8",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3 Chargement des meilleurs modèles \n",
    "\n",
    "Ensuite, on charge les modèles de texte et d'image qui donnent le meilleur score dans la phase d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737db0bf",
   "metadata": {},
   "source": [
    "### Load meilleur modèle text : Word2Vec (skip-gram) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3f7245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 450, 300)          18850800  \n",
      "                                                                 \n",
      " rnn (RNN)                   (None, 450, 128)          165120    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 450, 128)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                6939      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,055,883\n",
      "Trainable params: 205,083\n",
      "Non-trainable params: 18,850,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_text_W2V = load_model(\"text_W2V_skip-gram.h5\")\n",
    "\n",
    "model_text_W2V.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "063c8a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 198s 105ms/step\n",
      "468/468 [==============================] - 49s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "# propabilites des class pour text\n",
    "train_pred_txt = model_text_W2V.predict(X_train_txt)\n",
    "test_pred_txt = model_text_W2V.predict(X_test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1616a89e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score train : 0.8572382813152314\n",
      "accuracy score test : 0.7942021241066061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.39      0.58      0.47       561\n",
      "          40       0.56      0.64      0.60       442\n",
      "          50       0.84      0.85      0.84       286\n",
      "          60       0.94      0.89      0.91       159\n",
      "        1140       0.70      0.80      0.75       447\n",
      "        1160       0.90      0.87      0.88       665\n",
      "        1180       0.64      0.54      0.59       117\n",
      "        1280       0.67      0.78      0.72       875\n",
      "        1281       0.71      0.54      0.61       336\n",
      "        1300       0.94      0.93      0.94       920\n",
      "        1301       0.89      0.85      0.87       133\n",
      "        1302       0.85      0.74      0.79       447\n",
      "        1320       0.83      0.77      0.80       611\n",
      "        1560       0.84      0.77      0.80       905\n",
      "        1920       0.86      0.92      0.89       752\n",
      "        1940       0.78      0.78      0.78       121\n",
      "        2060       0.72      0.80      0.76       869\n",
      "        2220       0.82      0.81      0.81       154\n",
      "        2280       0.74      0.68      0.71       842\n",
      "        2403       0.76      0.71      0.73       869\n",
      "        2462       0.79      0.65      0.71       243\n",
      "        2522       0.94      0.92      0.93       919\n",
      "        2582       0.79      0.61      0.69       460\n",
      "        2583       0.94      0.98      0.96      1741\n",
      "        2585       0.70      0.76      0.73       450\n",
      "        2705       0.88      0.59      0.71       495\n",
      "        2905       1.00      0.99      0.99       152\n",
      "\n",
      "    accuracy                           0.79     14971\n",
      "   macro avg       0.79      0.77      0.78     14971\n",
      "weighted avg       0.80      0.79      0.80     14971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred_class_txt = np.argmax(train_pred_txt, axis=1)\n",
    "test_pred_class_txt = np.argmax(test_pred_txt, axis=1)\n",
    "\n",
    "train_pred_class_txt = encoder.inverse_transform(train_pred_class_txt)\n",
    "test_pred_class_txt = encoder.inverse_transform(test_pred_class_txt)\n",
    "\n",
    "y_train_class = encoder.inverse_transform(y_train)\n",
    "y_test_class = encoder.inverse_transform(y_test)\n",
    "\n",
    "print(\"accuracy score train :\", accuracy_score(y_train_class, train_pred_class_txt))\n",
    "print(\"accuracy score test :\", accuracy_score(y_test_class, test_pred_class_txt))\n",
    "print(classification_report(y_test_class, test_pred_class_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c781afee",
   "metadata": {},
   "source": [
    "### Load meilleur modèle image : EfficientNetB1 dé-freezé les 20 dernières couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03032097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb1 (Functional)  (None, 8, 8, 1280)       6575239   \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 27)                1856539   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,431,778\n",
      "Trainable params: 4,186,987\n",
      "Non-trainable params: 4,244,791\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_image_EfficientNetB1 = load_model(\"image_EfficientNetB1.h5\")\n",
    "\n",
    "model_image_EfficientNetB1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e59dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 1386s 739ms/step\n",
      "468/468 [==============================] - 337s 720ms/step\n"
     ]
    }
   ],
   "source": [
    "# probabilites des class pour image\n",
    "train_pred_img = model_image_EfficientNetB1.predict(train_set)\n",
    "test_pred_img = model_image_EfficientNetB1.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a8ffb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score train : 0.7562747357346826\n",
      "accuracy score test : 0.7571304522076013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.64      0.60      0.62       561\n",
      "          40       0.63      0.76      0.69       442\n",
      "          50       0.69      0.58      0.63       286\n",
      "          60       0.78      0.87      0.82       159\n",
      "        1140       0.68      0.79      0.73       447\n",
      "        1160       0.92      0.96      0.94       665\n",
      "        1180       0.77      0.62      0.68       117\n",
      "        1280       0.67      0.53      0.59       875\n",
      "        1281       0.68      0.36      0.47       336\n",
      "        1300       0.76      0.88      0.82       920\n",
      "        1301       0.79      0.77      0.78       133\n",
      "        1302       0.70      0.72      0.71       447\n",
      "        1320       0.77      0.63      0.70       611\n",
      "        1560       0.73      0.77      0.75       905\n",
      "        1920       0.84      0.89      0.86       752\n",
      "        1940       0.74      0.67      0.70       121\n",
      "        2060       0.68      0.72      0.70       869\n",
      "        2220       0.88      0.69      0.78       154\n",
      "        2280       0.79      0.78      0.79       842\n",
      "        2403       0.74      0.71      0.72       869\n",
      "        2462       0.78      0.67      0.72       243\n",
      "        2522       0.78      0.80      0.79       919\n",
      "        2582       0.75      0.56      0.64       460\n",
      "        2583       0.87      0.94      0.90      1741\n",
      "        2585       0.75      0.70      0.72       450\n",
      "        2705       0.72      0.84      0.77       495\n",
      "        2905       0.56      0.85      0.67       152\n",
      "\n",
      "    accuracy                           0.76     14971\n",
      "   macro avg       0.74      0.73      0.73     14971\n",
      "weighted avg       0.76      0.76      0.75     14971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_labels = dict((v,k) for k,v in (train_set.class_indices).items())\n",
    "\n",
    "train_pred_class_img = [int(fit_labels[i]) for i in np.argmax(train_pred_img, axis=1)]  \n",
    "test_pred_class_img = [int(fit_labels[i]) for i in np.argmax(test_pred_img, axis=1)]  \n",
    "\n",
    "y_train_class = encoder.inverse_transform(y_train)\n",
    "y_test_class = encoder.inverse_transform(y_test)\n",
    "\n",
    "print(\"accuracy score train :\", accuracy_score(y_train_class, train_pred_class_img))\n",
    "print(\"accuracy score test :\", accuracy_score(y_test_class, test_pred_class_img))\n",
    "print(classification_report(y_test_class, test_pred_class_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd2f8e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.4. Fusion des modèles texte et image\n",
    "\n",
    "Selon la recherche bibliographique, il existe plusieurs méthodes pour la construction d'un modèle multi-modal. Nous avons choisi l'approches qui adapte le plus à notre état actuel qui est une fusion au niveau de la décision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d9067",
   "metadata": {},
   "source": [
    "</b>\n",
    "Dans cette approche, on prend les class de propabilité predictes par les modèles de texte et image respectivement. On les concatene et ensuite réalise une classification finale via des couches de reseau de neurone Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddab3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation des probabilites des modèle texte et image\n",
    "train_pred_txt_img = np.concatenate([train_pred_txt, train_pred_img], axis=1)\n",
    "test_pred_txt_img = np.concatenate([test_pred_txt, test_pred_img], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3eb907d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14971, 54)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_txt_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d995bd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               28160     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                13851     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,011\n",
      "Trainable params: 42,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "\n",
    "model_fusion_proba = Sequential()\n",
    "model_fusion_proba.add(Input(shape=train_pred_txt_img.shape[1]))\n",
    "model_fusion_proba.add(Dense(512, activation='relu'))\n",
    "model_fusion_proba.add(Dense(27, activation='softmax'))\n",
    "\n",
    "model_fusion_proba.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eae2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.005, patience=5, mode='max', \n",
    "                               restore_best_weights=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ede58d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 0.4208 - accuracy: 0.8940 - val_loss: 0.4746 - val_accuracy: 0.8614\n",
      "Epoch 2/20\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 0.3214 - accuracy: 0.9029 - val_loss: 0.4631 - val_accuracy: 0.8639\n",
      "Epoch 3/20\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 0.3140 - accuracy: 0.9044 - val_loss: 0.4611 - val_accuracy: 0.8626\n",
      "Epoch 4/20\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 0.3085 - accuracy: 0.9047 - val_loss: 0.4582 - val_accuracy: 0.8642\n",
      "Epoch 5/20\n",
      "1872/1872 [==============================] - 5s 2ms/step - loss: 0.3031 - accuracy: 0.9053 - val_loss: 0.4576 - val_accuracy: 0.8614\n",
      "Epoch 6/20\n",
      "1850/1872 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.9064Restoring model weights from the end of the best epoch: 1.\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 0.2982 - accuracy: 0.9063 - val_loss: 0.4474 - val_accuracy: 0.8650\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a75a9d15d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fusion_proba.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_fusion_proba.fit(train_pred_txt_img, y_train, validation_data= [test_pred_txt_img, y_test],\n",
    "                       batch_size = 32, epochs=20,\n",
    "                       callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c75402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "fusion_test_pred_txt_img = model_fusion_proba.predict(test_pred_txt_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4ce7a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score test : 0.8613987041613786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.68      0.76      0.72       561\n",
      "          40       0.81      0.81      0.81       442\n",
      "          50       0.86      0.86      0.86       286\n",
      "          60       0.96      0.93      0.95       159\n",
      "        1140       0.81      0.89      0.85       447\n",
      "        1160       0.96      0.98      0.97       665\n",
      "        1180       0.82      0.68      0.74       117\n",
      "        1280       0.79      0.76      0.77       875\n",
      "        1281       0.68      0.71      0.69       336\n",
      "        1300       0.94      0.96      0.95       920\n",
      "        1301       0.94      0.88      0.91       133\n",
      "        1302       0.89      0.79      0.84       447\n",
      "        1320       0.84      0.84      0.84       611\n",
      "        1560       0.79      0.86      0.83       905\n",
      "        1920       0.91      0.91      0.91       752\n",
      "        1940       0.91      0.88      0.90       121\n",
      "        2060       0.81      0.79      0.80       869\n",
      "        2220       0.85      0.90      0.87       154\n",
      "        2280       0.88      0.80      0.84       842\n",
      "        2403       0.83      0.83      0.83       869\n",
      "        2462       0.82      0.76      0.79       243\n",
      "        2522       0.95      0.94      0.94       919\n",
      "        2582       0.79      0.68      0.74       460\n",
      "        2583       0.96      0.98      0.97      1741\n",
      "        2585       0.79      0.81      0.80       450\n",
      "        2705       0.89      0.90      0.90       495\n",
      "        2905       1.00      0.99      0.99       152\n",
      "\n",
      "    accuracy                           0.86     14971\n",
      "   macro avg       0.86      0.85      0.85     14971\n",
      "weighted avg       0.86      0.86      0.86     14971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fusion_test_pred_txt_img_class = np.argmax(fusion_test_pred_txt_img, axis=1)\n",
    "\n",
    "fusion_test_pred_txt_img_class = encoder.inverse_transform(fusion_test_pred_txt_img_class)\n",
    "y_test_class = encoder.inverse_transform(y_test)\n",
    "\n",
    "print(\"accuracy score test :\", accuracy_score(y_test_class, fusion_test_pred_txt_img_class))\n",
    "print(classification_report(y_test_class, fusion_test_pred_txt_img_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae7ae1",
   "metadata": {},
   "source": [
    "### 4.5. Conclusion sur l'agrégation des modèles\n",
    "\n",
    "Les scores d'accuracy des modèles unimodal et du modèle agrégé sont résumés comme suit:\n",
    "\n",
    "- Meilleur modèle de texte : **79.4 %**\n",
    "- Meilleur modèle d'image : **75.7 %**\n",
    "- Modèle agrégé : **86.1 %**\n",
    "\n",
    "Le modèle agrégé multi-modal a réussi à **augmenter la performance** de prediction d'environ **7%** par rapport au modèle unimodal de text. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-scientest",
   "language": "python",
   "name": "data-scientest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
